---
title: Operators
description: Core Building Blocks of LuminAIR
---

In LuminAIR, operators represent the fundamental operations that a computational graph executes.
Each operator is associated with an AIR component, which ensures integrity during proof generation.

# Primitive Operators

LuminAIR adopts a RISC-style architecture for its operators.
LuminAIR supports a minimal set of 11 primitive operators.
These operators are sufficient to implement a wide range of machine learning models, such as linear regression, convolutional networks, and transformers.

| Operator     | Status |
| ------------ | ------ |
| `Log2`       | ✅     |
| `Exp2`       | ⏳     |
| `Sin`        | ⏳     |
| `Sqrt`       | ⏳     |
| `Recip`      | ⏳     |
| `Add`        | ✅     |
| `Mul`        | ✅     |
| `Mod`        | ⏳     |
| `LessThan`   | ⏳     |
| `SumReduce`  | ✅     |
| `MaxReduce`  | ✅     |
| `Contiguous` | ✅     |

These primitive operators are handled by the `PrimitiveCompiler`, a subset of the `StwoCompiler`.
Each operator is mapped to its corresponding AIR component during compilation, ensuring compatibility with the proof generation process.

# High-Level Operators
While the primitive operators cover a wide range of models, they may not always be the most efficient choice.
Complex operations in machine learning often require multiple primitive operators, leading to large graphs with many nodes. This can slow down both execution and proof generation.

To address this, LuminAIR plans to introduce fused operators in future phases (see [Roadmap](/more/roadmap)).
These fused operators will combine multiple primitives into single optimized operations, reducing graph complexity and improving performance.

The exact list of fused operators is still under development, but priority will be given to commonly used ML operations such as MatMul, SoftMax or ReLU.
